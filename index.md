
## Projects


### Intrinsic Dimension of Data Representations in Deep Networks


<img src="/figs/intrinsic_dimension/wrap_up_no_letters.png" alt="Drawing" style="width: 400px;"/>


Deep neural networks transform their inputs across multiple layers.<br/>
In this Project we studied the intrinsic dimensionality (ID) of data-representations,<br/>
i.e. the minimal number of parameters needed to describe a representation.<br/>

We estimate ID in multiple CNNs with the [**TWO-NN**](https://www.nature.com/articles/s41598-017-11873-y) algorithm<br/>
and find that<br/>

- the ID is much lower than the number of units (ED, embedding dimensions)
- the ID along the layers has a typical “hunchback” shape
- in the last hidden layer the ID strongly predicts performance
- even in the last hidden layer, representations are curved.

Look inside [**the Repository**](https://github.com/ansuini/IntrinsicDimDeep) for an outline of our work, extra materials (long video, poster) and the code.<br/> 
Full details are in our [**NeurIPS 2019 paper**](https://arxiv.org/abs/1905.12784)


### Accuracy of Rats in Discriminating Visual Objects Is Explained by the Complexity of Their Perceptual Strategy

<img src="/figs/decision_images/summary.jpg" alt="Drawing" style="width: 600px;"/>

*Credits to [Marco Gigante](http://samba.sissa.it/users/marco-gigante) for his beautiful drawing.*

In this Project we studied the perceptual strategies of rats involved in
visual discrimination tasks.

With the aid of machine learning techniques based on **logistic regression**
and **classification images** we found that:

- the ability of rats to discriminate visual objects varies greatly across subjects
- such variability is accounted for by the diversity of rat perceptual strategies
- animals building richer perceptual templates achieve higher accuracy
- perceptual strategies remain largely invariant across object transformations


For this work, we had the honour to receive a referral by Philippe G.Schyns in [**Current Biology**](https://www.sciencedirect.com/science/article/pii/S0960982218302446).

Full details are in the [**paper**](https://www.sciencedirect.com/science/article/pii/S0960982218302227).
